{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sources:\n",
    "- http://crtm.maps.arcgis.com/home/item.html?id=1a25440bf66f499bae2657ec7fb40144\n",
    "- https://data.renfe.com/dataset/volumen-de-viajeros-por-franja-horaria-madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from statistics import mean\n",
    "from decimal import Decimal as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/madrid/'\n",
    "PARSED_PATH = DATA_PATH + 'parsed/'\n",
    "\n",
    "if not os.path.exists(PARSED_PATH):\n",
    "    os.mkdir(PARSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to missing data in the timetables, skip some stations and lines\n",
    "skip_stations = {\n",
    "    'COLMENAR VIEJO': [],\n",
    "    'TRES CANTOS': [],\n",
    "    'GOLOSO EL': [],\n",
    "    'SANTA MARIA DE LA ALAMEDA': [],\n",
    "    'ROBLEDO DE CHAVELA': [],\n",
    "    'ZARZALEJO': [],\n",
    "    'ESCORIAL EL': [],\n",
    "    'ZORRERAS LAS': [],\n",
    "    'SAN YAGO': [],\n",
    "    'VILLALBA': ['C3'],\n",
    "    'GALAPAGAR-LA NAVATA': ['C3'],\n",
    "    'TORRELODONES': ['C3'],\n",
    "    'MATAS LAS': ['C3'],\n",
    "    'PINAR DE LAS ROZAS': ['C3'],\n",
    "    'PITIS': ['C3'],\n",
    "    'MIRASIERRA-PACO DE LUCIA': [],\n",
    "    'RAMON Y CAJAL': ['C3']\n",
    "}\n",
    "skip_lines = ['C9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_times = pd.read_csv(DATA_PATH + 'trains/stop_times.txt', index_col=False)\n",
    "stops = pd.read_csv(DATA_PATH + 'trains/stops.txt', index_col=False)\n",
    "trips = pd.read_csv(DATA_PATH + 'trains/trips.txt', index_col=False)\n",
    "routes = pd.read_csv(DATA_PATH + 'trains/routes.txt', index_col=False)\n",
    "turnstiles = pd.read_csv(DATA_PATH + 'turnstiles.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "route2line = {}\n",
    "for i, row in routes.iterrows():\n",
    "    route2line[row['route_id']] = row['route_short_name']\n",
    "\n",
    "stop2name = {}\n",
    "for i, row in stops.iterrows():\n",
    "    stop2name[row['stop_id']] = row['stop_name']\n",
    "\n",
    "trip2route = {}\n",
    "for i, row in trips.iterrows():\n",
    "    trip2route[row['trip_id']] = row['route_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stations of each line\n",
    "stations_in_line = {}\n",
    "lines_in_station = {}\n",
    "\n",
    "for i, row in stop_times.iterrows():\n",
    "    line_name = route2line[trip2route[row['trip_id']]]\n",
    "    from_station = stop2name[row['stop_id']]\n",
    "    \n",
    "    if line_name in skip_lines:\n",
    "        continue\n",
    "    elif from_station in skip_stations and (line_name in skip_stations[from_station] or len(skip_stations[from_station]) == 0):\n",
    "        continue\n",
    "    \n",
    "    if line_name not in stations_in_line:\n",
    "        stations_in_line[line_name] = set()\n",
    "    if from_station not in lines_in_station:\n",
    "        lines_in_station[from_station] = set()\n",
    "    \n",
    "    stations_in_line[line_name].add(from_station)\n",
    "    lines_in_station[from_station].add(line_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix turnstile initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all stations in connections are in the turnstiles table\n",
    "remove_rows = []\n",
    "for i, row in turnstiles.iterrows():\n",
    "    st_name = row['STATION_NAME']\n",
    "    if st_name not in skip_stations:\n",
    "        continue\n",
    "    \n",
    "    skip_in_lines = skip_stations[st_name]\n",
    "    \n",
    "    if len(skip_in_lines) == 0:\n",
    "        remove_rows.append(i)\n",
    "\n",
    "\n",
    "for st_name, skip_in_lines in skip_stations.items():\n",
    "    if st_name not in lines_in_station:\n",
    "        continue\n",
    "    \n",
    "    lines = lines_in_station[st_name]\n",
    "    \n",
    "    if len(skip_in_lines) == 0:\n",
    "        del lines_in_station[st_name]\n",
    "        stations_in_line = {l:[s for s in stations if s != st_name] for l, stations in stations_in_line.items()}\n",
    "    else:\n",
    "        skip_in_lines = [l for l in skip_in_lines if l in lines]\n",
    "        if skip_in_lines == 0:\n",
    "            # Consider as already deleted\n",
    "            continue\n",
    "        \n",
    "        lines_in_station[st_name] = [l for l in lines_in_station[st_name] if l not in skip_in_lines]\n",
    "        stations_in_line = {l:[s for s in stations if s != st_name and l == skip_in_lines] for l, stations in stations_in_line.items()}\n",
    "\n",
    "        if len(lines_in_station[st_name]) == 0:\n",
    "            del lines_in_station[st_name]\n",
    "\n",
    "turnstiles = turnstiles.drop(remove_rows)\n",
    "turnstiles = turnstiles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles.to_csv(PARSED_PATH + 'turnstiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles = pd.read_csv(PARSED_PATH + 'turnstiles.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected stations\n",
    "\n",
    "Note that trains may skip some stations (fast routes) so, in such cases, I consider that a station is connected to the next non-skipped station too.\n",
    "\n",
    "The final CSV should be: `station_connections.csv`\n",
    "- `LINE`\n",
    "- `FROM_STATION`\n",
    "- `TO_STATION`\n",
    "- `DIRECTION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = {\n",
    "    'LINE': [],\n",
    "    'FROM_STATION': [],\n",
    "    'TO_STATION': [],\n",
    "    'DIRECTION': []\n",
    "}\n",
    "connections = pd.DataFrame(connections, columns=connections.keys()).astype({'DIRECTION': 'int32'})\n",
    "\n",
    "for i, row in stop_times.iterrows():\n",
    "    stop_sequence = row['stop_sequence']\n",
    "    next_station = stop_times.loc[(stop_times['trip_id'] == row['trip_id']) & (stop_times['stop_sequence'] == stop_sequence + 1)]\n",
    "    \n",
    "    if next_station.size == 0:\n",
    "        continue\n",
    "    \n",
    "    direction = trips.loc[trips['trip_id'] == row['trip_id']].iloc[0]['direction_id']\n",
    "    direction = int(direction)\n",
    "    \n",
    "    next_station = next_station.iloc[0]\n",
    "    \n",
    "    line_name = route2line[trip2route[row['trip_id']]]\n",
    "    from_station = stop2name[row['stop_id']]\n",
    "    to_station = stop2name[next_station['stop_id']]\n",
    "    \n",
    "    if line_name in skip_lines:\n",
    "        continue\n",
    "\n",
    "    s_row = pd.Series({'LINE': line_name, 'FROM_STATION': from_station, 'TO_STATION': to_station, 'DIRECTION': direction})\n",
    "    connections = connections.append(s_row, ignore_index=True)\n",
    "    \n",
    "connections.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.to_csv(PARSED_PATH + 'station_connections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = pd.read_csv(PARSED_PATH + 'station_connections.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stations\n",
    "found_rows = True\n",
    "while found_rows:\n",
    "    to_remove = []\n",
    "    to_append = []\n",
    "    found_rows = False\n",
    "    \n",
    "    for i, row in connections.iterrows():\n",
    "        st_name = row['TO_STATION']\n",
    "        line_name = row['LINE']\n",
    "        direction = row['DIRECTION']\n",
    "\n",
    "        if st_name not in skip_stations:\n",
    "            continue\n",
    "\n",
    "        skip_st_lines = skip_stations[st_name]\n",
    "        if len(skip_st_lines) > 0:\n",
    "            if line_name not in skip_st_lines:\n",
    "                continue\n",
    "            else:\n",
    "                conditions = (connections['LINE'] == line_name) & (connections['DIRECTION'] == direction)\n",
    "        else:\n",
    "            conditions = (connections['DIRECTION'] == direction)\n",
    "\n",
    "\n",
    "        st_skip = connections.loc[(connections['FROM_STATION'] == st_name) & conditions]\n",
    "\n",
    "        prev_stations = []\n",
    "        next_stations = st_skip['TO_STATION'].tolist()\n",
    "        to_remove = to_remove + list(st_skip.index)\n",
    "        \n",
    "        for st_skip_i, st_skip_row in st_skip.iterrows():\n",
    "            st_prev = connections.loc[(connections['TO_STATION'] == st_name) & conditions]\n",
    "            for _, st_prev_row in st_prev.iterrows():\n",
    "                if len(next_station) > 0:\n",
    "                    prev_stations.append(st_prev_row['FROM_STATION'])\n",
    "            to_remove = to_remove + list(st_prev.index)\n",
    "\n",
    "        for prev_station in prev_stations:\n",
    "            for next_station in next_stations:\n",
    "                s_row = pd.Series({'LINE': line_name, 'FROM_STATION': prev_station,\n",
    "                                   'TO_STATION': next_station, 'DIRECTION': direction})\n",
    "                to_append.append(s_row)\n",
    "        \n",
    "        \n",
    "    connections = connections.drop(to_remove)\n",
    "    for row in to_append:\n",
    "        connections = connections.append(row, ignore_index=True)\n",
    "\n",
    "    connections = connections.reset_index(drop=True)\n",
    "    connections.drop_duplicates(keep='first', inplace=True)\n",
    "    \n",
    "    found_rows = len(to_remove) > 0 or len(to_append) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.to_csv(PARSED_PATH + 'station_connections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = pd.read_csv(PARSED_PATH + 'station_connections.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "# Check that all stations in connections are in the turnstiles table\n",
    "\n",
    "for i, row in turnstiles.iterrows():\n",
    "    st_name = row['STATION_NAME']\n",
    "    \n",
    "    exists = connections.loc[connections['FROM_STATION'] == st_name]\n",
    "    if exists.size == 0:\n",
    "        raise Exception('Unknown station: %s' % st_name)\n",
    "\n",
    "print('Ok!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timetable\n",
    "\n",
    "The final file `timetable.csv` should be as follows:\n",
    "- `ID`: unique ID which represents the train or the vehicle.\n",
    "- `LINE`: Name of the line.\n",
    "- `ARRIVAL_TIME`: None or datetime.time (None if it is the first station).\n",
    "- `DEPARTURE_TIME`: None or datetime.time (None if it is the last station).\n",
    "- `STATION_NAME`: Station name.\n",
    "- `NEXT_STATION`: Name of the next station.\n",
    "- `IS_START`: 1 if it is the starting station of the route.\n",
    "- `IS_END`: 1 if it is the ending station of the route.\n",
    "- `DIRECTION`: 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable = {\n",
    "    'ID': [],\n",
    "    'LINE': [],\n",
    "    'ARRIVAL_TIME': [],\n",
    "    'DEPARTURE_TIME': [],\n",
    "    'STATION_NAME': [],\n",
    "    'NEXT_STATION': [],\n",
    "    'IS_START': [],\n",
    "    'IS_END': [],\n",
    "    'DIRECTION': []\n",
    "}\n",
    "timetable = pd.DataFrame(timetable, columns=timetable.keys()).astype({'ID': 'int32', 'DIRECTION': 'int32',\n",
    "                                                                      'IS_START': 'int32', 'IS_END': 'int32'})\n",
    "\n",
    "trip_ids = stop_times['trip_id'].unique()\n",
    "trip2train = {trip_id:i for i, trip_id in enumerate(trip_ids)}\n",
    "\n",
    "# We must fix the timezone of the data\n",
    "time_offset = 1\n",
    "\n",
    "for i, row in stop_times.iterrows():\n",
    "    stop_sequence = row['stop_sequence']\n",
    "    next_station = stop_times.loc[(stop_times['trip_id'] == row['trip_id']) & (stop_times['stop_sequence'] == stop_sequence + 1)]\n",
    "    \n",
    "    train_id = int(trip2train[row['trip_id']])\n",
    "    line_name = route2line[trip2route[row['trip_id']]]\n",
    "    station_name = stop2name[row['stop_id']]\n",
    "    \n",
    "    direction = trips.loc[trips['trip_id'] == row['trip_id']].iloc[0]['direction_id']\n",
    "    direction = int(direction)\n",
    "    \n",
    "    if line_name in skip_lines:\n",
    "        continue\n",
    "    \n",
    "    if next_station.size > 0:\n",
    "        next_station = next_station.iloc[0]\n",
    "        next_station = stop2name[next_station['stop_id']]\n",
    "    else:\n",
    "        next_station = None\n",
    "    \n",
    "    arrival_time = row['arrival_time'].split(':')\n",
    "    arrival_hour = int(arrival_time[0]) + time_offset if int(arrival_time[0]) + time_offset < 24 else 0\n",
    "    arrival_time = datetime.time(arrival_hour, int(arrival_time[1]))\n",
    "    \n",
    "    departure_time = row['departure_time'].split(':')\n",
    "    departure_hour = int(departure_time[0]) + time_offset if int(departure_time[0]) + time_offset < 24 else 0\n",
    "    departure_time = datetime.time(departure_hour, int(departure_time[1]))\n",
    "    \n",
    "    is_start = int(stop_sequence) == 0\n",
    "    is_end = next_station is None\n",
    "\n",
    "    s_row = pd.Series({'ID': train_id, 'LINE': line_name, 'ARRIVAL_TIME': arrival_time,\n",
    "                       'DEPARTURE_TIME': departure_time, 'STATION_NAME': station_name,\n",
    "                       'NEXT_STATION': next_station, 'IS_START': is_start, 'IS_END': is_end,\n",
    "                       'DIRECTION': direction})\n",
    "    timetable = timetable.append(s_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stations\n",
    "found_rows = True\n",
    "while found_rows:\n",
    "    found_rows = False\n",
    "    to_remove = []\n",
    "    for skip_station_name, skip_lines in skip_stations.items():\n",
    "        if len(skip_lines) == 0:\n",
    "            st_timetable = timetable.loc[(timetable['STATION_NAME'] == skip_station_name)]\n",
    "        else:\n",
    "            st_timetable = timetable.loc[(timetable['STATION_NAME'] == skip_station_name) &\n",
    "                                         (timetable['LINE'].isin(skip_lines))]\n",
    "\n",
    "        for i, row in st_timetable.iterrows():\n",
    "            found_rows = True\n",
    "            prev_timetable = timetable.loc[(timetable['NEXT_STATION'] == row['STATION_NAME']) &\n",
    "                                           (timetable['ID'] == row['ID'])]\n",
    "            has_previous_station = (prev_timetable.size > 0)\n",
    "\n",
    "            next_timetable = timetable.loc[(timetable['STATION_NAME'] == row['NEXT_STATION']) &\n",
    "                                           (timetable['ID'] == row['ID'])]\n",
    "            has_next_station = (next_timetable.size > 0)\n",
    "            \n",
    "            for next_i, next_row in next_timetable.iterrows():\n",
    "                if not has_previous_station:\n",
    "                    timetable.at[prev_i, 'IS_START'] = 1\n",
    "            \n",
    "            for prev_i, prev_row in prev_timetable.iterrows():\n",
    "                if not has_next_station:\n",
    "                    timetable.at[prev_i, 'DEPARTURE_TIME'] = row['ARRIVAL_TIME']\n",
    "                    timetable.at[prev_i, 'NEXT_STATION'] = None\n",
    "                    timetable.at[prev_i, 'IS_END'] = 1\n",
    "                else:\n",
    "                    timetable.at[prev_i, 'NEXT_STATION'] = next_timetable.iloc[0]['STATION_NAME']\n",
    "                \n",
    "            to_remove.append(i)\n",
    "\n",
    "    timetable = timetable.drop(to_remove)\n",
    "    timetable = timetable.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable.to_csv(PARSED_PATH + 'timetable.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable = pd.read_csv(PARSED_PATH + 'timetable.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights of lines\n",
    "\n",
    "Based on the average number of IN-passengers of the stations of the line, compute the weight of the line in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lines = {\n",
    "    'LINE': [],\n",
    "    'WEIGHT_IN': [],\n",
    "    'WEIGHT_OUT': []\n",
    "}\n",
    "w_lines = pd.DataFrame(w_lines, columns=w_lines.keys())\n",
    "\n",
    "all_line_inweights = {}\n",
    "all_line_outweights = {}\n",
    "\n",
    "for i, row in turnstiles.iterrows():\n",
    "    # Get name of station and all the lines in the station\n",
    "    st_name = row['STATION_NAME']\n",
    "    line_names = lines_in_station[st_name]\n",
    "    \n",
    "    in_count = D(row['IN']) / len(line_names)\n",
    "    out_count = D(row['OUT']) / len(line_names)\n",
    "    \n",
    "    for line_name in line_names:\n",
    "        if line_name not in all_line_inweights:\n",
    "            all_line_inweights[line_name] = []\n",
    "            all_line_outweights[line_name] = []\n",
    "        \n",
    "        all_line_inweights[line_name].append(in_count)\n",
    "        all_line_outweights[line_name].append(out_count)\n",
    "\n",
    "# Calculate means\n",
    "all_line_inweights = {line_name:mean(w) for line_name, w in all_line_inweights.items()}\n",
    "all_line_outweights = {line_name:mean(w) for line_name, w in all_line_outweights.items()}\n",
    "\n",
    "# Normalize and store\n",
    "norm_in = D(sum(list(all_line_inweights.values())))\n",
    "norm_out = D(sum(list(all_line_outweights.values())))\n",
    "\n",
    "line_names = timetable['LINE'].unique()\n",
    "for line_name in line_names:\n",
    "    weight_in = all_line_inweights[line_name]\n",
    "    weight_out = all_line_outweights[line_name]\n",
    "    \n",
    "    weight_in = D(weight_in) / norm_in\n",
    "    weight_out = D(weight_out) / norm_out\n",
    "    \n",
    "    s_row = pd.Series({'LINE': line_name, 'WEIGHT_IN': weight_in, 'WEIGHT_OUT': weight_out})\n",
    "    w_lines = w_lines.append(s_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lines.to_csv(PARSED_PATH + 'line_weights.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lines = pd.read_csv(PARSED_PATH + 'line_weights.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights of stations in the line\n",
    "\n",
    "Depending on the time, each station of the line has a specific weight.\n",
    "\n",
    "**TO DO:** It should be calculated using some kind of continuous probability function.\n",
    "\n",
    "**Note**: The sum of weights of all stations (in the same time) on each line must be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_w_lines = w_lines.set_index(['LINE']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEROPUERTO T4 (83 of 83)                                     \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "w_stations = {\n",
    "    'LINE': [],\n",
    "    'STATION_NAME': [],\n",
    "    'TIME': [],\n",
    "    'WEIGHT_IN': [],\n",
    "    'WEIGHT_OUT': []\n",
    "}\n",
    "w_stations = pd.DataFrame(w_stations, columns=w_stations.keys()).set_index(['LINE', 'STATION_NAME', 'TIME'])\n",
    "\n",
    "all_line_weights = {}\n",
    "\n",
    "debug_prev_station = None\n",
    "debug_i = 0\n",
    "debug_len = len(turnstiles['STATION_NAME'].unique())\n",
    "for i, row in turnstiles.iterrows():\n",
    "    if row['STATION_NAME'] != debug_prev_station:\n",
    "        debug_prev_station = row['STATION_NAME']\n",
    "        debug_i = debug_i + 1\n",
    "        print('\\r%s (%d of %d)'% (row['STATION_NAME'], debug_i, debug_len), ' '*20, end='')\n",
    "    \n",
    "    # Get the length of the time interval in the turnstile table\n",
    "    time_range = [t.strip().split(':') for t in turnstiles.at[i, 'TIME_INTERVAL'].split('-')]\n",
    "    delta_start = datetime.timedelta(hours=int(time_range[0][0]), minutes=int(time_range[0][1]))\n",
    "    delta_end = datetime.timedelta(hours=int(time_range[1][0]), minutes=int(time_range[1][1]))\n",
    "    \n",
    "    if delta_end < delta_start:\n",
    "        delta_mid = datetime.timedelta(hours=23, minutes=59)\n",
    "        total_seconds = (delta_mid - delta_start).total_seconds()\n",
    "        \n",
    "        total_seconds = total_seconds + delta_end.total_seconds()\n",
    "        \n",
    "        n_minutes = int((total_seconds) // 60) + 1\n",
    "    else:\n",
    "        total_seconds = (delta_end - delta_start).total_seconds()\n",
    "        n_minutes = int(total_seconds // 60)\n",
    "    \n",
    "    # Get name of station and all the lines in the station\n",
    "    st_name = row['STATION_NAME']\n",
    "    line_names = lines_in_station[st_name]\n",
    "    \n",
    "    in_count = D(row['IN']) / n_minutes\n",
    "    out_count = D(row['OUT']) / n_minutes\n",
    "    \n",
    "    lines_station_weight_in = w_lines.loc[w_lines['LINE'].isin(line_names)]['WEIGHT_IN'].sum()\n",
    "    lines_station_weight_out = w_lines.loc[w_lines['LINE'].isin(line_names)]['WEIGHT_OUT'].sum()\n",
    "    time_ref = datetime.datetime(100, 1, 1, int(time_range[0][0]), int(time_range[0][1]), 0)\n",
    "    \n",
    "    for line_name in line_names:\n",
    "        # If the station is shared with more lines, get the weight of the line\n",
    "        line_weight_in = dict_w_lines['WEIGHT_IN'][line_name]\n",
    "        line_weight_out = dict_w_lines['WEIGHT_OUT'][line_name]\n",
    "        w_in = D(line_weight_in) / D(lines_station_weight_in)\n",
    "        w_out = D(line_weight_out) / D(lines_station_weight_out)\n",
    "        \n",
    "        # Add one row per minute\n",
    "        for k in range(n_minutes):\n",
    "            k_time = (time_ref + datetime.timedelta(minutes=k)).time()\n",
    "            \n",
    "            s_row = pd.Series({'WEIGHT_IN': in_count * w_in,\n",
    "                               'WEIGHT_OUT': out_count * w_out}, name=(line_name, st_name, k_time))\n",
    "            w_stations = w_stations.append(s_row)\n",
    "\n",
    "print('\\nDone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_stations.to_csv(PARSED_PATH + 'station_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>WEIGHT_IN</th>\n",
       "      <th>WEIGHT_OUT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LINE</th>\n",
       "      <th>STATION_NAME</th>\n",
       "      <th>TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">C10</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">PRINCIPE PIO</th>\n",
       "      <th>00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00:01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00:02:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00:03:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00:04:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            WEIGHT_IN  WEIGHT_OUT\n",
       "LINE STATION_NAME TIME                           \n",
       "C10  PRINCIPE PIO 00:00:00        0.0    0.104674\n",
       "                  00:01:00        0.0    0.104674\n",
       "                  00:02:00        0.0    0.104674\n",
       "                  00:03:00        0.0    0.104674\n",
       "                  00:04:00        0.0    0.104674"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data\n",
    "w_stations = pd.read_csv(PARSED_PATH + 'station_weights.csv', index_col=['LINE', 'STATION_NAME', 'TIME'])\n",
    "\n",
    "w_normstations = w_stations.copy()\n",
    "time_groups = w_stations.groupby(['LINE', 'TIME']).sum()\n",
    "\n",
    "for i, row in w_normstations.iterrows():\n",
    "    line_name = i[0]\n",
    "    time = i[2]\n",
    "    norm_in = D(time_groups.at[(line_name, time), 'WEIGHT_IN'])\n",
    "    norm_out = D(time_groups.at[(line_name, time), 'WEIGHT_OUT'])\n",
    "    w_normstations.at[i, 'WEIGHT_IN'] = D(0) if norm_in == 0 else D(w_normstations.at[i, 'WEIGHT_IN']) / norm_in\n",
    "    w_normstations.at[i, 'WEIGHT_OUT'] = D(0) if norm_out == 0 else D(w_normstations.at[i, 'WEIGHT_OUT']) / norm_out\n",
    "\n",
    "w_normstations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_normstations.to_csv(PARSED_PATH + 'norm_station_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_normstations = pd.read_csv(PARSED_PATH + 'norm_station_weights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_times = {\n",
    "    'TIME': [],\n",
    "    'WEIGHT_IN': [],\n",
    "    'WEIGHT_OUT': []\n",
    "}\n",
    "w_times = pd.DataFrame(w_times, columns=w_times.keys()).set_index('TIME')\n",
    "\n",
    "for i, row in turnstiles.iterrows():\n",
    "    # Get the length of the time interval in the turnstile table\n",
    "    time_range = [t.strip().split(':') for t in turnstiles.at[i, 'TIME_INTERVAL'].split('-')]\n",
    "    delta_start = datetime.timedelta(hours=int(time_range[0][0]), minutes=int(time_range[0][1]))\n",
    "    delta_end = datetime.timedelta(hours=int(time_range[1][0]), minutes=int(time_range[1][1]))\n",
    "    \n",
    "    if delta_end < delta_start:\n",
    "        delta_mid = datetime.timedelta(hours=23, minutes=59)\n",
    "        total_seconds = (delta_mid - delta_start).total_seconds()\n",
    "        \n",
    "        total_seconds = total_seconds + delta_end.total_seconds()\n",
    "        \n",
    "        n_minutes = int((total_seconds) // 60) + 1\n",
    "    else:\n",
    "        total_seconds = (delta_end - delta_start).total_seconds()\n",
    "        n_minutes = int(total_seconds // 60)\n",
    "    \n",
    "    in_count = D(row['IN']) / n_minutes\n",
    "    out_count = D(row['OUT']) / n_minutes\n",
    "    \n",
    "    # Add one row per minute\n",
    "    time_start = datetime.datetime(100, 1, 1, int(time_range[0][0]), int(time_range[0][1]), 0)\n",
    "    for k in range(n_minutes):\n",
    "        k_time = (time_start + datetime.timedelta(minutes=k)).time()\n",
    "        \n",
    "        if k_time not in w_times.index:\n",
    "            w_times = w_times.append(pd.Series({'WEIGHT_IN': D(0), 'WEIGHT_OUT': D(0)}, name=k_time))\n",
    "\n",
    "        w_times.at[k_time, 'WEIGHT_IN'] = w_times.at[k_time, 'WEIGHT_IN'] + in_count\n",
    "        w_times.at[k_time, 'WEIGHT_OUT'] = w_times.at[k_time, 'WEIGHT_OUT'] + out_count\n",
    "\n",
    "w_times['WEIGHT_IN'] = w_times['WEIGHT_IN'] / turnstiles['IN'].sum()\n",
    "w_times['WEIGHT_OUT'] = w_times['WEIGHT_OUT'] / turnstiles['OUT'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_times.to_csv(PARSED_PATH + 'times_weights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinates of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_coords = {\n",
    "    'STATION_NAME': [],\n",
    "    'X': [],\n",
    "    'Y': []\n",
    "}\n",
    "stations_coords = pd.DataFrame(stations_coords, columns=stations_coords.keys()).set_index('STATION_NAME')\n",
    "\n",
    "station_names = connections.reset_index()['FROM_STATION'].unique()\n",
    "\n",
    "for i, row in stops.iterrows():\n",
    "    if row['stop_name'] not in station_names:\n",
    "        continue\n",
    "    \n",
    "    stations_coords = stations_coords.append(pd.Series({'X': row['stop_lon'],\n",
    "                                                        'Y': row['stop_lat']}, name=row['stop_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_coords.to_csv(PARSED_PATH + 'station_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
